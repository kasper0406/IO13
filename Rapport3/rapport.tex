\documentclass[a4paper,12pt]{article}
\usepackage[T1]{fontenc}
\usepackage[latin9]{inputenc}
\usepackage{listings}
\usepackage{amsmath}
\usepackage{mathtools}
\usepackage{hyperref}
\usepackage{mathpazo}
\usepackage{wasysym}
\usepackage{graphicx}
\usepackage[colorinlistoftodos]{todonotes}
\usepackage{natbib} 
\usepackage{geometry}
\usepackage{tikz}
\geometry{verbose,tmargin=2.5cm,bmargin=2.5cm,lmargin=3cm,rmargin=3cm}

\DeclarePairedDelimiter{\ceil}{\lceil}{\rceil}
\DeclarePairedDelimiter{\floor}{\lfloor}{\rfloor}
\newcommand{\ord}{\operatorname{ord}}

\newcommand*\circled[1]{\tikz[baseline=(char.base)]{
            \node[shape=circle,draw,inner sep=2pt] (char) {#1};}}

\begin{document}

\title{I/O-algorithms\\Project 3}

\author{Lasse Espeholt - 20093223\\
Kasper Nielsen - 20091182\\}

\maketitle

\pagebreak{}\tableofcontents{}\pagebreak{}

\section{Sorting}
\textbf{Problem:} Design an I/O-efficient algorithm for removing duplicate from a multiset of $N$ elements.
\\
\\As given in the hint in the exercise, the algorithm is based on mergesort, where duplicates are removed as soon as they are found in the merge step.

The algorithm will be analyzed by giving an upper bound on the number of times an element is scanned during an execution of the algorithm. For illustration purposes consider Figure~\ref{fig:sorting:mergetree}. Since duplicates are removed as soon as they are found, no node in the merge tree can contain duplicates (the leaves are found by sorting the elements in internal memory and removing duplicates).

\begin{figure}[h!]
  \centering
  \includegraphics[width=0.8\textwidth]{images/mergetree}
  \caption{Example merge tree of height $3$ with fanout $d = 3$. Illustrates how many duplicates there can be on every level of the merge tree.}
  \label{fig:sorting:mergetree}
\end{figure}

Therefore for a given level $l$ in the merge tree of fanout $d$ and height $H$, at most $d^l$ duplicates remain. Furthermore, there are at most $N_i$ duplicates of a given element $i$. Therefore, the total number of duplicates remaining on level $i$ is less than $\min\{d^l, N_i\}$. Summing the contribution from all levels of the tree gives an upper bound on the number of times a given element is scanned. This can again be summed over all different elements, giving the following upper bound on the total number of element scans
\[
  \sum_{i=1}^K \sum_{l = 0}^H \min\{N_i, d^l\} .
\]
Notice that $N_i \leq d^l \iff \log_d{N_i} \leq l$. Therefore, if $H_i := \floor{\log_d{N_i}}$, then
\[
  \sum_{i=1}^K \sum_{l = 0}^H \min\{N_i, d^l\} \leq
    \sum_{i=1}^K \left( \sum_{l=0}^{H_i} d^l + \sum_{l = H_i + 1}^H N_i \right) =
    \underbrace{\sum_{i=1}^K \sum_{l=0}^{H_i} d^l}_{\circled{1}} + \underbrace{\sum_{i=1}^K \sum_{l = H_i + 1}^H N_i}_{\circled{2}}.
\]
An upper bound is given on \circled{1} and \circled{2}:
\begin{description}
\item[\circled{1}] Notice that
  \begin{align*}
    \sum_{l=0}^{H_i} d^l = \frac{d^{H_i + 1} - 1}{d - 1} = \frac{d d^{\floor{\log_d{N_i}}} - 1}{d - 1} \leq \frac{d}{d - 1} N_i .
  \end{align*}
  When summing over all elements, it is found that
  \[
    \circled{1} \leq \sum_{i=1}^K \frac{d}{d - 1} N_i = \frac{d}{d - 1} N.
  \]
  By the tall cache assumption $d = \frac{M}{B} \geq B \geq 2$ (otherwise it is an internal memory algorithm). Therefore $\frac{d}{d - 1} \leq 2$, hence $\circled{1} = O(N)$.

\item[\circled{2}] For this bound, notice that
  \begin{align*}
    \sum_{l = H_i + 1}^{H} N_i &= \left( H - (H_i + 1) \right) N_i
      = \left( \log_d{\frac{N}{M}} - (\floor{\log_d{N_i}} + 1) \right) N_i \\
      &\leq \left( \log_d{\frac{N}{M}} - \log_d{N_i} \right) N_i
      = N_i \log_d{\frac{N}{M}} - N_i \log_d{N_i}.
  \end{align*}
  By summing over all elements, it is found that
  \[
    \circled{2} \leq \sum_{i=1}^K N_i \log_{\frac{M}{B}}{\frac{N}{M}} - N_i \log_{\frac{M}{B}}{N_i}
      = O\left( N \log_{\frac{M}{B}}{\frac{N}{B}} - \sum_{i = 1}^K N_i \log_{\frac{M}{B}}{N_i} \right).
  \]
\end{description}
Combining theses two bounds, it is found that at most
\[
  \sum_{i=1}^K \sum_{l = 0}^H \min\{N_i, d^l\} = O(N) + O\left( N \log_{\frac{M}{B}}{\frac{N}{B}} - \sum_{i = 1}^K N_i \log_{\frac{M}{B}}{N_i} \right)
\]
elements are scanned during the algorithm. The algorithm always scans elements in blocks, however some of the blocks could be non-full due to the duplicate removal. However, this can only happen once for every node in the merge tree, which is asymptotically bounded by the number of leaves ($\frac{N}{M} \leq \frac{N}{B}$). Therefore this cost and the cost of the first input scan are bounded by $O(\frac{N}{B})$, whereby the total number of I/Os is bounded by
\begin{align*}
  O\left( \max\left\{ \frac{N}{B}, \frac{N \log_{\frac{M}{B}}{\frac{N}{B}} - \sum_{i = 1}^K N_i \log_{\frac{M}{B}}{N_i}}{B} \right\} \right) \\
    = O\left( \max\left\{ \frac{N}{B}, \frac{N}{B} \log_{\frac{M}{B}}{\frac{N}{B}} - \sum_{i=1}^K \frac{N_i}{B} \log_{\frac{M}{B}}{N_i} \right\} \right).
\end{align*}

\pagebreak
\section{Searching}

\textbf{Problem:} Design a linear space external data structure for the problem of maintaining a set of intervals $I$, such that given a query point $x$ the number of intervals in $I$ containing $x$.
\\
\\The problem is very closely related to the one solved by the external interval tree -- instead of reporting the stabbed intervals, they should be counted. However, this means that some of the complexity of the data structure can not be hidden behind the output complexity. In order to circumvent this problem, the following modifications are made to the external interval tree:
\begin{itemize}
  \item The slab lists associated to a node are stored as weight balanced B-trees.
  \item A counter is associated to all multislab lists, maintaining the number of intervals in the multislab. These counters also stores the counts for the intervals put in the underflow structure.

\iffalse
  \item In addition to the underflow structure, a counting underflow structure is maintained. The static structure for answering interval queries used in the underflow structure is modified such that it can answer counting stabbing queries in time $O(\log_B N)$ I/Os. This is done by sweeping the intervals from left to right, and maintain a counter of the number of currently active intervals. For all start or endpoints of intervals, the current number of active intervals is inserted into a B-tree. Thereby a counting stabbing query can be answered by searching down the B-tree. Clearly this structure uses linear space and can be constructed in $O(\frac{N}{B} \log_{\frac{M}{B}}{\frac{N}{B}})$ I/Os.

  Notice that instead of storing the counting underflow structure, it could be omitted and then simply store the counts in the counters for the multislabs. However, we have chosen not to do this in order to have a more clear correspondence with the external interval tree.
\fi
\end{itemize}
Since the original external interval tree uses linear space, the structure with the above modifications still uses linear space.

Queries are answered by walking down the base tree based on the query point. When processing a node in the tree the counts for the multislab lists are read using $O(1)$ I/O, and the relevant interval counts are summed. Then the associated structure to the node is queried as described below using $O(\log_B N)$ I/Os. In total, the query complexity is $O(\log_B^2 N)$ I/Os.

When querying the associated data-structures, it should be counted how many elements are located to the left (right) of a given point. In the original external interval tree, this is done by scanning the elements, and then charging the cost to the output size. However, this is not possible when counting. Instead, a query is answered by walking down the tree according to the query point while counting the number of elements in the sub-trees to the left (right) by using their weights.

Figure~\ref{fig:searching:query} illustrates the query process for counting the number of intervals in the left slab lists. The querying process is started in the root, and is then moving down the tree. Every internal node stores the weights of all the children, which can be read using $O(1)$ I/Os, and can also be updated without a problem during insertion/deletion. In order to find the number of intervals with an start point to the to the left of the query point, the children of $v$ located to the left of the child $v'$ containing the query point is summed up, and a recursive call is made on $v'$.
\begin{figure}[h!]
  \centering
  \includegraphics[width=0.6\textwidth]{images/query}
  \caption{Answering a query in a left slab list structure. The weights of the leafs to the left of $v'$ is summed up to get the number of intervals with a start point to the left of the query point.}
  \label{fig:searching:query}
\end{figure}
This produces $O(1)$ I/Os at every node and since the tree is balanced, contributes a total of $O(\log_B N)$ I/Os.

The insertion / deletion process is almost the same as for the external interval tree\footnote{We assume the version without global rebuilding when doing deletions.}. The only difference is that the counters for the multislabs needs to be updated, but this can easily be done when updating the elements inside each multislab. Note that using a weight balanced B-tree for the slab lists does not change how the slab lists are updated. Using the same analysis as in the lecture notes, the complexity for doing inserts and deletes is $O(\log_B N)$ I/Os amortized.

\pagebreak
\section{Distribution sweeping}

\input{3.tex}

%\bibliographystyle{plain}
%\addcontentsline{toc}{section}{\refname}\bibliography{ref}

\end{document}
