%!TEX root = rapport.tex
This section presents details on how the heap has
been implemented. Also the details of
all the implemented streams are discussed.

\subsection{Notation}
\label{sec:implementation:parameters}

We use the following variables throughout the rapport:

\begin{itemize}
  \item $V$ is the maximum number of elements in a node in the heap. Hence, a
    node is imperfect if it contains less than $\left\lceil \frac{V}{2}
    \right\rceil$ elements.
  \item $d$ is the fan-out of the heap.
  \item $B$ is the buffer size of buffered streams.
  \item $N$ is the number of elements.
  \item $M$ is the amount of main memory available.
\end{itemize}

\subsection{Heap}
In the paper, the structure of the heap was represented using pointers
such that every node stores pointers to its children and its
parent.

Instead, we chose to have an internal array representation of the heap where
each entry corresponds to a node in the heap. Then for a given node, the
index of the parent and the indices of
the children can be calculated using simple integer operations.
To store the elements of the heap, a big file have been allocated on
disk. This file is (virtually) divided into blocks of size $V$, such
that each node in the internal heap is associated with a block.
Using this representation, it is also very easy to swap the position
of two nodes, as the two entries in the array can simply be swapped
(this is required in the insert operation when the last node is
imperfect).

When elements are inserted into the heap, the file may become too
small. Hence, when a new block is added and the file does not have
enough space, the file is extended by $V$ elements. Extending the file
should be handled by the operating system using constant I/Os, and
hence there should be no problem in extending the file every time a new
node is added.

Every node in the tree has an associated stream that can read and
write to the block associated with the node. Unless mentioned otherwise,
the stream for a given node is opened and
closed as it is needed. That is, every time an element is read
or written, the stream is opened, the operations are executed,
and then the stream is closed again. This also means that at
most $d + 1$ streams are open at the same time, which happens in
the refill operation.

\begin{figure}
  \centering
  \includegraphics[width=6cm]{node_block}
  \caption{Layout of a block associated with a node. Elements are
    stored in decreasing sorted order, and is placed from right to left.}
  \label{fig:node-block}
\end{figure}

Elements are stored from right to left in the block in
descending sorted order, as illustrated by
figure~\ref{fig:node-block}. This layout facilitates forward reading
when extracting the maximum elements.

\subsubsection{Sifting}
\label{sec:heap:sifting}
During sifting, the elements in the child node and its parent are merged.
When doing this, one should be careful
about how many elements are assigned to respectively the parent and
the child node after the merge: If too many elements are transferred
to the parent, such that an element with strictly lower priority than the minimum element in the parent is
added, then the heap invariant between the parent and
its other children may be violated.

On the other hand, it is desired to assign as many elements as
possible to the parent node, as this may delay future refill
operations.

In the paper they assign $\max(r - h, \ceil*{\frac{V}{2}})$ elements to
the child, where $r$ is the sum of the number of elements in the
parent and in the child node, and $h$ is the number of elements
having priority higher than or equal to the smallest element in the parent node.
One situation where this strategy does not work is when two full blocks are merged, and $h =
0$ (that is, all the child elements are smaller than the elements in the parent),
then all elements will be assigned to the child, which renders the
parent node imperfect.

We have fixed this by assigning
\[
  \max \left( \text{child elements less than minimum in parent}, \ceil*{\frac{V}{2}} \right)
\]
elements to the child. This may overfill the parent but in that case a sufficient amount of elements
are transfered to the child node. By construction
this will satisfy the invariants of the heap.
\\
\\
Two implementations have been made for merging a block:
\begin{description}
\item[Memory inefficient] version where $2V$ elements are buffered
  and the merging is done in internal memory. This approach has the
  advantage that it only reads forward.
\item[Memory efficient] version where only $V$ elements are
  buffered. The problem with this implementation is to determine how
  many elements should go to the child and to the parent, without
  reading the unbuffered block several times.

  In order to get around this problem, the minimum element in all
  nodes have been cached, which means that the number of elements
  going to the child node (and the parent) can be computed when
  reading the elements of the child node into the buffer. Then the
  elements going to the child node can be written backwards into its
  block by reading the buffer and the block of the parent node
  backwards.
\end{description}

We have chosen to make experiments with both techniques, as we were unsure about
the penalty of reading and writing backwards, due to read-ahead,
etc.

\subsubsection{Verifying correctness}
To ensure the correctness of our heap implementation, the following
four techniques have been used during testing:
\begin{itemize}
\item Unit testing of the individual methods.
\item A graphical representation of the data structure have been
  implemented, enabling us to manually verify small test inputs.
\item A consistency check function has been implemented, which is
  called after every insert and extract operation. The consistency
  check function makes a recursive decent of the nodes in the heap,
  and check that all invariants are satisfied.
\item A sanity test function have been made, where $10^6$
  uniformly random integers was inserted into the heap, and then
  extracted afterwards. It was tested that the integers came out in
  sorted order.
\end{itemize}
All of the above checks passes in our implementation.

\subsection{Streams}

To support the heap structure, the stream interface supported the following operations:

\begin{description}
\item[{\texttt{open}}] Opens the stream for read/write.
\item[{\texttt{close}}] Closes the stream and deallocates buffers if necessary.
\item[{\texttt{peek}}] Peeks at the current location.
\item[{\texttt{read\_next}}] Reads at the current location and advances the location.
\item[{\texttt{read\_prev}}] Reads at the current location and moves back.
\item[{\texttt{write}}] Writes at the current location and advances the location.
\item[{\texttt{backward\_write}}] Writes at the current location and moves back.
\item[{\texttt{position}}] Return the current location.
\item[{\texttt{seek}}] Changes the location.
\end{description}

\texttt{read\_prev} and \texttt{backward\_write} were needed for the memory efficient sifting algorithm.

\subsubsection{BufferedStream}

The implementation of buffered stream was slightly more complex than the implementation in project 1 because of the extended stream interface with methods like \texttt{seek} and \texttt{read\_prev}. However, we made a few improvements to make the implementation as efficient as possible. One of the improvements included heuristics for choosing the portion of the file that ends in the buffer. For example, if the requested element is not in the buffer and is at the location right after the buffer ends, then the next portion from the element and onwards is buffered. This improvement could also have been implemented by supplying hints to how the stream is used. Furthermore, a 'write bitmap' were used to determine exactly what needs to be written to disk. This can be important for large buffer sizes.

% TODO: Read map

For the buffered stream, the stream associated with the root node was kept open to avoid filling the buffer from disk on each 'extract max' operation.

\subsubsection{MMapStream}

In project 1, the memory mapped stream mapped blocks of the file when they were needed. This is not the most natural way to utilize memory mapped files. Instead, the memory mapped stream used in this project maps the whole file once and remaps the file if the file size changes. In this way, the operating system is completely in charge of utilizing file caches in the best possible way.

We did test an implementation that worked by mapping blocks when they were needed, but the overhead of remapping made it slower than just mapping the entire file.

\subsubsection{Cached stream}

To make it very fast to retrieve the maximum element of especially the root but also other nodes, a cached stream was implemented. It caches reads but propagates writes to the underlying stream. The cache is always filled by reading forward.

The caching is very important for the analysis of the algorithm. If no cache were used in the root node, every extract max operation would result in an I/O. Hence, the algorithm would have the complexity $O(N\log \frac{N}{B})$ instead of $O(\frac{N}{B}\log \frac{N}{B})$. Furthermore, in the refill operation all the children's maximum elements is cached which also would result in additional I/Os.

\subsubsection{Other streams}

A stream named SysStream using the POSIX methods \texttt{read} and \texttt{write} and a stream named FStream using \texttt{fread} and \texttt{fwrite} were also implemented. The stream interface almost mapped one-to-one and are therefore not explained in more detail.

The buffer size of \texttt{fread}/\texttt{fwrite} on our system was 4 kB, which can be found with the constant \texttt{BUFSIZ} in \texttt{<cstdio>}.

Similarly to BufferedStream, FStream keeps the stream associated with the root node open.

