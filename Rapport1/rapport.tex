\documentclass[a4paper,12pt]{article}
\usepackage[T1]{fontenc}
\usepackage[latin9]{inputenc}
\usepackage{listings}
\usepackage{amsmath}
\usepackage{mathtools}
\usepackage{mathpazo}
\usepackage{wasysym}
\usepackage{graphicx}
\usepackage{tikz,pgfplots}
\usepackage[colorinlistoftodos]{todonotes}
\usepackage{natbib} 
\usepackage{geometry}
\usetikzlibrary{fit,shapes.misc,snakes}
\geometry{verbose,tmargin=2.5cm,bmargin=2.5cm,lmargin=2.5cm,rmargin=2.5cm}

\newcommand{\ord}{\operatorname{ord}}

\graphicspath{ {../Project1/measurements/final/} }

\begin{document}

\title{IO\\Project 1}

\author{Lasse Espeholt - 20093223\\
Kasper Nielsen - 20091182\\}

\maketitle
\begin{figure}[h!]
\includegraphics[width=\textwidth]{"images/forside"}
\end{figure}


\vfill{}
\begin{description}
\item [{Implementation~code~and~test~results:}]
\texttt{http://github.com/kasper0406/IO13/}
\end{description}
\pagebreak{}\tableofcontents{}\pagebreak{}

- Memory compressing
- SSd
- caching (memory

\section{Introduction}
\input{introduction.tex}

\section{Setup}
This section presents the test setup, how measurements are performed
and gives an overview of the files attached to this report.

\subsection{Test setup}
All measurements presented in this report were performed on a computer
with an Intel Core i3-380UM CPU with the following technical
specifications:
\begin{itemize}
\item 2 cores operating at 1.33GHz.
\item 2 x 32KB L1 data cache. 2 x 256 KB L2 cache. Shared 3MB L3 cache.
\end{itemize}
The main memory size of the machine is 1 GB (with 600 - 700 MB free memory), and was running Ubuntu
Linux 12.04. The storage was an external USB2 attached 250 GB, 5,400 RPM hard drive.

All implementations have been
written in \texttt{C++11} and compiled on Linux using the GCC 4.7 compiler. When measurements were performed, the
code was compiled using the \texttt{-O3 -flto -funroll-loops}
optimization flags.

In the beginning we ran our tests 3 times. However, it turned out the
variance of our measurements was very small, and to make it feasible
to run our tests on bigger inputs, we adjusted our tests to only
one trial for large inputs.

\subsection{File structure}
The following is a description of the different folders handed in with
the report.
\begin{description}
\item[code] Contains the implementations of the different streams and
  the external memory sort.

\item[output] Contains the raw measurements used for the plots in the
  report. The plots themselves are also included in a pdf-format.
\end{description}

\subsubsection{Code structure}
The code has the following source files.
\begin{description}
\item[main.cpp] Driver code for calling test code.
\item[Test.hpp] Test framework for generating inputs and measuring
  running times.
\item[CMakeLists.txt] CMake file for the project specifying
  compilation options.

\item Describe rest!\todo{Do this and correct filenames!}
\end{description}

\section{Streams}
This section will present how we benchmarked the four different
streams, and an analysis of their performance. First each stream will
be treated separately and the best settings for each stream will be
used in a relative performance benchmark for finding the stream most
suitable for sorting.

In order to mimic the behaviour of sorting during the test, we have
tested the streams in respectively reading / writing $n$ elements from
/ to a file. Each test uses $k$ interleaved streams to do this, such
that a new stream is starting at every $\frac{n}{k}$ elements, and
elements are being processed in a round robin fashion of the streams.

All tests of the streams have used $n = 2^{28}$, which corresponds to
1GB of elements\todo{Ikke sandt, det er kun 1GB elementer vi har testet paa. Ellers ville MMap read ogsaa vaere meget maerkelige! Maaske vi for Mmap skulle lave en 2GB test}. This choice was made to make sure the data was
located on the disk, and still small enough to be able to run all the tests within reasonably time. The
value of $n$ has not been varied for the stream test, as it is not
expected that streams will behave differently, as long as the data is
big enough to not fit the main memory.

In the merge step in the sorting application, the input streams are
used in a very similar way, the output streams are however only used
in the $k = 1$ case\todo{?}, but we have chosen to do testing of these streams
for varying values of $k$, to be able to get comparable results
between input and output streams.

\subsection{Buffered streams}
\label{sec:buffered-streams}
This type of stream is implemented using the \texttt{read} and
\texttt{write} POSIX system calls. On top of those, a buffer of size
$B$ is maintained keeping track of the next elements to read or write.

It will be investigated how the choice of buffer size and varying
values of $k$ influences the
performance. Figure~\ref{fig:buffered-input} shows a plot of this for
the input stream.

\begin{figure}[h!]
  \centering
  \includegraphics[width=0.8\textwidth]{buffered_input_low}
  \caption{Running times for the buffered input stream using different
    buffer sizes and varying $k$-values.}
  \label{fig:buffered-input}
\end{figure}

From Figure~\ref{fig:buffered-input} it seems like all the streams
perform about the same for sequential read ($k = 1$), which is the
case where the operating system and disk controller is also easily
able to employ caching on lower levels.

As $k$ gets bigger, Figure~\ref{fig:buffered-input} indicates that
bigger buffers gives better performance, which was expected. However,
for large buffer sizes in combination with large values of $k$, the
input stream performs extremely poorly. The slowness is because the
buffers in this case resides on disk, whereby buffering is worse than
using no buffer at all. Larger choices of buffer size was also tried,
which as expected showed a similar behaviour, and is therefore of no
interest for use in sorting\todo{Comment on ``curve'' for small buffers in plot.}.

From Figure~\ref{fig:buffered-input}, it seems that a buffer size of 2
MB provides the best compromise of running time and memory usage for
the input stream in the sorting application.

For the output stream a similar plot is shown in
Figure~\ref{fig:buffered-output}.

\begin{figure}[h!]
  \centering
  \includegraphics[width=0.8\textwidth]{buffered_output_low}
  \caption{Running times for the buffered output stream using different
    buffer sizes and varying $k$-values.}
  \label{fig:buffered-output}
\end{figure}

It is expected that the plots in Figure~\ref{fig:buffered-input} and
Figure~\ref{fig:buffered-output} are similar, since the two streams
are much alike. However, it is seen that the varying the buffer size
almost have no effect on the performance of the output streams, except
when they are too big to be in memory\todo{This seems to happen before
  in the write case?}.

Another experiment was performed to explain this behaviour, where the
\texttt{fsync(2)}\footnote{The \texttt{fsync(2)} system call ensures
  that the file is written to disk immediately.} system call was
called immediately after each write operation. It was found that both
the input and output streams performed very similar, hence the absence
of effect in buffer size change showed in
Figure~\ref{fig:buffered-output} can be explained by the operating
system delaying writes to the disk.

A buffer size of 2 MB has been chosen to give the best trade-off
between running time and memory consumption. From
Figure~\ref{fig:buffered-output} it seems like a tiny buffer would be
a better choice, but if the operating system for some reason fails
delay writes in the sorting application, a buffer size of 2 MB
provides more confidence that the stream will actually perform as
expected when used in sorting.

\subsection{MMap streams}
For the memory mapped streams, the \texttt{mmap} and \texttt{munmap}
system calls are used for mapping a file into memory. Then the file
can be accessed as it was loaded into memory, but the actual loading
is lazy, such that it only happens when it is actually needed.

Therefore it is expected that the block size mapped into memory each
time \texttt{mmap} is called, will not have any significant impact on
the results, since only some memory bookkeeping and different amount
of remapping is required when using different block sizes. This
however, should be negligible compared to the time of the actual disk
access.

\begin{figure}[h!]
  \centering
  \includegraphics[width=0.8\textwidth]{mmap_input}
  \caption{Running times for the mmap input stream, varying sizes of
    mapped blocks and $k$-values.}
  \label{fig:mmap-input}
\end{figure}

Figure~\ref{fig:mmap-input} shows a plot of the running times for the
mmapped input stream. Except for the case $k = 256$, the plot shows
that the running times for the different block sizes are very close,
which is expected. For the $k = 256$ case, it seems like some choices
of block sizes are better than other, but there does not seem to be an
obvious correlation on how the block sizes influences the running time
in this case. This may simply be because of variance in the
measurements\todo{Try to do more trials.}.

The running time of input stream was found to be worse when the value
of $k$ was increased. This can be explained by that the disk have to
read data located farther away from each other when a new page is
loaded into memory. This takes longer time, because the disk have to
move its read heads\todo{Other reasons?}.

\begin{figure}[h!]
  \centering
  \includegraphics[width=0.8\textwidth]{mmap_output}
  \caption{Running times for the mmap output stream, varying sizes of
    mapped blocks and $k$-values.}
  \label{fig:mmap-output}
\end{figure}

A similar plot for the mmap output stream is shown at
Figure~\ref{fig:mmap-output}. For the output stream it seems like the
different streams behaves alike for different buffer sizes, except
when the block size is 8kB. The 8kB block performs substantially
better when $k = 1$, but worse when $k = 4$\todo{Why?}.

Like the input stream, the performance of the output stream is
decreasing for larger values of $k$, and no test with $k$ greater than
16 was performed due to long execution times\todo{Do this?}.

\subsection{Other streams}
\label{sec:other-streams}
This section will discuss the two remaining stream
implementations. The first of these are the streams using the
\texttt{fwrite} and \texttt{fread} C standard library calls, which
themselves do buffering. At our test machine the default buffer size
of \texttt{fread} and \texttt{fwrite} was 8
kB. Figure~\ref{fig:fstreams} shows a plot of their performance.

\begin{figure}[h!]
  \centering
  \includegraphics[width=0.8\textwidth]{fstreams}
  \caption{Running times for the streams using the \texttt{fwrite} and
    \texttt{fread} standard library functions, varying the values of
    $k$.}
  \label{fig:fstreams}
\end{figure}

Comparing Figure~\ref{fig:fstreams} to our buffered streams, they show
a very similar behaviour. This is as expected, since the streams
should function in exactly the same way.

We will now turn our attention to the streams using the \texttt{read}
and \texttt{write} system calls directly. Due to extremely poor
performance, only one measurement for the output stream was
obtained. The results are plotted in Figure~\ref{fig:syscall-streams}.

\begin{figure}[h!]
  \centering
  \includegraphics[width=0.8\textwidth]{syscall_streams}
  \caption{Running times for the streams using the \texttt{write} and
    \texttt{read} system calls directly, varying the values of $k$.}
  \label{fig:syscall-streams}
\end{figure}

The input stream has an almost constant running time from $k$ between
1 and 16. However, for $k = 64$ a small increase in running time is
seen, which ...\todo{Describe why?}.

As mentioned earlier, only one measurement was done for the output
stream. It is a bit surprising that the output stream is so much
slower than the input stream. The the smallest unit able to be written
to the disk is a sector\todo{block?}, which on the test machine is
512B\todo{Check this.}. If smaller amount should be written, it is
required that the sector is read, modified in memory and then written
back to the disk. When the \texttt{write} system call is used without
buffering, this happens every time an integer is written to the
stream, causing a tremendous overhead, resulting in the extremely
large running time.

\subsection{Relative comparison}
In order to determine which stream to use, it is very important that
the input streams performs well for varying values of $k$. This
however, is not as important for the output stream since it is not
interleaved, but other disk access may happen in between writes to the
output stream in the sorting, meaning that it is also is preferable if
the output stream performs decently for different $k$ values, as this
indicate that the output stream is more robust for interleaved disk
operations.

In order to chose which stream to use in sorting, we have picked out
the input and output streams from the previous sections, which had the
best performance across all values of $k$. In this section we will
compare them, and single out a winner for use in sorting.

Figure~\ref{fig:best-input} shows the running times for what was found
to be the best input streams. This plot suggests that the buffered
input stream with 2MB buffer is the best choice, whereby we have
chosen to use this for sorting.

\begin{figure}[h!]
  \centering
  \includegraphics[width=0.8\textwidth]{best_input}
  \caption{Comparison of the best input streams from each of the four
    types of streams.}
  \label{fig:best-input}
\end{figure}

Figure~\ref{fig:best-output} shows a plot of the best output
streams. The only real competition is between the \texttt{fwrite} and
the buffered output stream with 2MB buffer. As discussed in
Section~\ref{sec:other-streams} the streams are functioning in almost
the same way, except they use a different buffer size. From the extra
experiment performed in Section~\ref{sec:buffered-streams}, it was
found that a small buffer was significantly worse if data was forced
to be written to the disk instantly after the buffer is full. This is
the case for sorting, since the operations in the next iteration
relies on these data. Therefore we have chosen to use the buffered
output stream with a 2MB buffer, even though
Figure~\ref{fig:best-output} seems to suggest it is performing
slightly worse at $k = 256$\todo{Do another plot justifying this?}.

\begin{figure}[h!]
  \centering
  \includegraphics[width=0.8\textwidth]{best_output}
  \caption{Comparison of the best output streams from each of the four
    types of streams.}
  \label{fig:best-output}
\end{figure}

\section{Sorting}

\subsection{Comparison with conventional sorting algorithms}

\section{Conclusion}
\input{conclusion.tex}

\clearpage{}\bibliographystyle{plain}
\addcontentsline{toc}{section}{\refname}\bibliography{ref}

\end{document}
